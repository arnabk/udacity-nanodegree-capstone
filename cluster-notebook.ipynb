{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Open         High          Low        Close    Adj Close  \\\n",
      "count  2482.000000  2482.000000  2482.000000  2482.000000  2482.000000   \n",
      "mean     44.292787    44.709990    43.866951    44.302997    42.602746   \n",
      "std      16.937181    17.033162    16.824473    16.928553    17.487494   \n",
      "min      19.334764    19.706724    19.084406    19.291845    17.654158   \n",
      "25%      30.758226    31.058655    30.332619    30.745708    28.350945   \n",
      "50%      40.207439    40.520000    39.841316    40.164520    38.219450   \n",
      "75%      60.147501    60.612499    59.654999    60.137500    58.809592   \n",
      "max      85.680000    85.680000    85.110001    85.449997    85.269928   \n",
      "\n",
      "             Volume        N - 1        N - 2        N - 3        N - 4  ...  \\\n",
      "count  2.482000e+03  2482.000000  2482.000000  2482.000000  2482.000000  ...   \n",
      "mean   3.389063e+06     0.025978     0.052151     0.078428     0.104745  ...   \n",
      "std    2.242013e+06     0.711997     0.981776     1.193218     1.372635  ...   \n",
      "min    2.719000e+05    -8.316132    -7.158215    -9.399109    -9.299759  ...   \n",
      "25%    1.844900e+06    -0.287933    -0.417211    -0.474327    -0.576760  ...   \n",
      "50%    2.815400e+06     0.038790     0.098099     0.130918     0.174219  ...   \n",
      "75%    4.297725e+06     0.397077     0.568015     0.739679     0.877797  ...   \n",
      "max    2.536860e+07     4.856430     5.466675     6.133827     6.567558  ...   \n",
      "\n",
      "             TRIMA          SAR    MACD-main  MACD-signal    MACD-hist  \\\n",
      "count  2482.000000  2482.000000  2482.000000  2482.000000  2482.000000   \n",
      "mean     43.937106    44.072087     0.168969     0.165587     0.003383   \n",
      "std      16.693944    16.900064     0.698305     0.646884     0.229438   \n",
      "min      20.214533    19.084406    -2.884965    -2.635140    -1.090179   \n",
      "25%      30.649701    30.499446    -0.257774    -0.232346    -0.123174   \n",
      "50%      40.075146    39.828568     0.214769     0.211145     0.009129   \n",
      "75%      59.742167    58.834082     0.613008     0.585638     0.137577   \n",
      "max      82.204000    84.980003     2.133623     1.950127     0.942030   \n",
      "\n",
      "               RSI      STOCH-k      STOCH-d            AD          ATR  \n",
      "count  2482.000000  2482.000000  2482.000000  2.482000e+03  2482.000000  \n",
      "mean     53.526882    55.495160    55.503638  2.479733e+08     0.919814  \n",
      "std      11.185371    25.527560    23.578592  7.071402e+07     0.354088  \n",
      "min      12.432980     1.831295     4.891891  2.194284e+07     0.342434  \n",
      "25%      45.681128    33.954262    35.821492  2.291390e+08     0.673547  \n",
      "50%      53.740614    57.862863    57.002541  2.508403e+08     0.818155  \n",
      "75%      62.034239    78.572220    76.273847  3.073190e+08     1.044215  \n",
      "max      80.949948    99.307675    98.078544  3.480531e+08     2.552671  \n",
      "\n",
      "[8 rows x 27 columns]\n",
      "Index(['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'N - 1', 'N - 2',\n",
      "       'N - 3', 'N - 4', 'N - 5', 'N - 6', 'N - 7', 'N - 8', 'N - 9', 'N - 10',\n",
      "       'Label', 'TRIMA', 'SAR', 'MACD-main', 'MACD-signal', 'MACD-hist', 'RSI',\n",
      "       'STOCH-k', 'STOCH-d', 'AD', 'ATR'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Training in AWS\n",
    "import sagemaker\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker import KMeans\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "local_data_folder = './data/'\n",
    "prefix = \"udacity-capstone-project\"\n",
    "ticker = 'A'\n",
    "\n",
    "A_df = pd.read_pickle(local_data_folder + ticker + '.pkl')\n",
    "A_df.dropna(inplace=True)\n",
    "A_df.drop(columns=[\"Date\"], inplace=True)\n",
    "print(A_df.describe())\n",
    "print(A_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "Y_df = pd.DataFrame(A_df[\"Label\"]).astype('float64')\n",
    "X_df = A_df.drop(columns=[\"Label\"]).astype('float64')\n",
    "\n",
    "X = scaler.fit_transform(X_df)\n",
    "Y = scaler.fit_transform(Y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.33, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-10 02:21:48 Starting - Starting the training job...\n",
      "2020-02-10 02:21:51 Starting - Launching requested ML instances...\n",
      "2020-02-10 02:22:48 Starting - Preparing the instances for training.........\n",
      "2020-02-10 02:24:09 Downloading - Downloading input data\n",
      "2020-02-10 02:24:09 Training - Downloading the training image..\u001b[34mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'_enable_profiler': u'false', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'_kvstore': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'true', u'epochs': u'1', u'init_method': u'random', u'local_lloyd_tol': u'0.0001', u'local_lloyd_max_iter': u'300', u'_disable_wait_to_read': u'false', u'extra_center_factor': u'auto', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'half_life_time_size': u'0', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'feature_dim': u'26', u'k': u'3', u'force_dense': u'True'}\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Final configuration: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'26', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'3', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 WARNING 140049681737536] Loggers have already been setup.\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Using default worker.\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Loaded iterator creator application/x-recordio-protobuf for content type ('application/x-recordio-protobuf', '1.0')\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Create Store: local\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] nvidia-smi took: 0.0252220630646 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Setting up with params: {u'_tuning_objective_metric': u'', u'extra_center_factor': u'auto', u'local_lloyd_init_method': u'kmeans++', u'force_dense': u'True', u'epochs': u'1', u'feature_dim': u'26', u'local_lloyd_tol': u'0.0001', u'_disable_wait_to_read': u'false', u'eval_metrics': u'[\"msd\"]', u'_num_kv_servers': u'1', u'mini_batch_size': u'5000', u'_enable_profiler': u'false', u'_num_gpus': u'auto', u'local_lloyd_num_trials': u'auto', u'_log_level': u'info', u'init_method': u'random', u'half_life_time_size': u'0', u'local_lloyd_max_iter': u'300', u'_kvstore': u'auto', u'k': u'3', u'_num_slices': u'1'}\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] 'extra_center_factor' was set to 'auto', evaluated to 10.\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] number of center slices 1\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 WARNING 140049681737536] Batch size 5000 is bigger than the first batch data. Effective batch size used to initialize is 1662\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1662, \"sum\": 1662.0, \"min\": 1662}, \"Total Batches Seen\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Total Records Seen\": {\"count\": 1, \"max\": 1662, \"sum\": 1662.0, \"min\": 1662}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1662, \"sum\": 1662.0, \"min\": 1662}, \"Reset Count\": {\"count\": 1, \"max\": 0, \"sum\": 0.0, \"min\": 0}}, \"EndTime\": 1581301471.152943, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"init_train_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1581301471.152901}\n",
      "\u001b[0m\n",
      "\u001b[34m[2020-02-10 02:24:31.153] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 0, \"duration\": 20, \"num_examples\": 1, \"num_bytes\": 212736}\u001b[0m\n",
      "\u001b[34m[2020-02-10 02:24:31.184] [tensorio] [info] epoch_stats={\"data_pipeline\": \"/opt/ml/input/data/train\", \"epoch\": 1, \"duration\": 31, \"num_examples\": 1, \"num_bytes\": 212736}\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] processed a total of 1662 examples\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"Max Batches Seen Between Resets\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Batches Since Last Reset\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"Number of Records Since Last Reset\": {\"count\": 1, \"max\": 1662, \"sum\": 1662.0, \"min\": 1662}, \"Total Batches Seen\": {\"count\": 1, \"max\": 2, \"sum\": 2.0, \"min\": 2}, \"Total Records Seen\": {\"count\": 1, \"max\": 3324, \"sum\": 3324.0, \"min\": 3324}, \"Max Records Seen Between Resets\": {\"count\": 1, \"max\": 1662, \"sum\": 1662.0, \"min\": 1662}, \"Reset Count\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}}, \"EndTime\": 1581301471.185482, \"Dimensions\": {\"Host\": \"algo-1\", \"Meta\": \"training_data_iter\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\", \"epoch\": 0}, \"StartTime\": 1581301471.153254}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] #throughput_metric: host=algo-1, train throughput=51250.4558107 records/second\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 WARNING 140049681737536] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] shrinking 30 centers into 3\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #0. Current mean square distance 0.222171\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #1. Current mean square distance 0.210378\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #2. Current mean square distance 0.210378\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #3. Current mean square distance 0.221870\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #4. Current mean square distance 0.243024\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #5. Current mean square distance 0.213880\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #6. Current mean square distance 0.224061\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #7. Current mean square distance 0.231197\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #8. Current mean square distance 0.278391\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] local kmeans attempt #9. Current mean square distance 0.255587\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] finished shrinking process. Mean Square Distance = 0\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] #quality_metric: host=algo-1, train msd <loss>=0.210378184915\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] compute all data-center distances: inner product took: 21.5056%, (0.008529 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] collect from kv store took: 21.3445%, (0.008465 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] splitting centers key-value pair took: 21.0643%, (0.008354 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] batch data loading with context took: 8.7392%, (0.003466 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] compute all data-center distances: point norm took: 6.8257%, (0.002707 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] gradient: cluster center took: 6.8130%, (0.002702 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] gradient: one_hot took: 4.9091%, (0.001947 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] predict compute msd took: 4.7005%, (0.001864 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] gradient: cluster size  took: 1.5282%, (0.000606 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] update state and report convergance took: 1.3869%, (0.000550 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] update set-up time took: 0.6426%, (0.000255 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] compute all data-center distances: center norm took: 0.4845%, (0.000192 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] predict minus dist took: 0.0559%, (0.000022 secs)\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] TOTAL took: 0.0396592617035\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 126.33991241455078, \"sum\": 126.33991241455078, \"min\": 126.33991241455078}, \"initialize.time\": {\"count\": 1, \"max\": 16.318798065185547, \"sum\": 16.318798065185547, \"min\": 16.318798065185547}, \"model.serialize.time\": {\"count\": 1, \"max\": 0.16188621520996094, \"sum\": 0.16188621520996094, \"min\": 0.16188621520996094}, \"update.time\": {\"count\": 1, \"max\": 32.00817108154297, \"sum\": 32.00817108154297, \"min\": 32.00817108154297}, \"epochs\": {\"count\": 1, \"max\": 1, \"sum\": 1.0, \"min\": 1}, \"state.serialize.time\": {\"count\": 1, \"max\": 0.8730888366699219, \"sum\": 0.8730888366699219, \"min\": 0.8730888366699219}, \"_shrink.time\": {\"count\": 1, \"max\": 124.33600425720215, \"sum\": 124.33600425720215, \"min\": 124.33600425720215}}, \"EndTime\": 1581301471.313451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1581301471.132005}\n",
      "\u001b[0m\n",
      "\u001b[34m[02/10/2020 02:24:31 INFO 140049681737536] Test data is not provided.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 249.05109405517578, \"sum\": 249.05109405517578, \"min\": 249.05109405517578}, \"setuptime\": {\"count\": 1, \"max\": 14.60409164428711, \"sum\": 14.60409164428711, \"min\": 14.60409164428711}}, \"EndTime\": 1581301471.313839, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/KMeansWebscale\"}, \"StartTime\": 1581301471.313559}\n",
      "\u001b[0m\n",
      "\n",
      "2020-02-10 02:24:40 Uploading - Uploading generated training model\n",
      "2020-02-10 02:24:40 Completed - Training job completed\n",
      "Training seconds: 51\n",
      "Billable seconds: 51\n",
      "CPU times: user 632 ms, sys: 27.6 ms, total: 659 ms\n",
      "Wall time: 3min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# clustering\n",
    "s3_output_folder = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "\n",
    "kmeans = KMeans(role=role,\n",
    "               train_instance_count=1,\n",
    "               train_instance_type=\"ml.m4.xlarge\",\n",
    "               output_path=s3_output_folder,\n",
    "               k=3)\n",
    "\n",
    "kmeans.fit(kmeans.record_set(pd.DataFrame(x_train).astype('float32').values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-west-2-825285592721/udacity-capstone-project/output/kmeans-2020-02-10-02-21-48-724/output/model.tar.gz\n",
      "-------------------!"
     ]
    }
   ],
   "source": [
    "# deploy\n",
    "print(kmeans.model_data)\n",
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1,\n",
    "             instance_type=\"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clusters for data\n",
    "def clustering(data):\n",
    "    clustering_result = kmeans_predictor.predict(pd.DataFrame(data).astype('float32').values)\n",
    "    clustering_result = list(map(lambda x:x.label[\"closest_cluster\"].float32_tensor.values[0], clustering_result))\n",
    "\n",
    "    assert len(clustering_result) == len(data), \"Length mis-match with clustering and input data\"\n",
    "\n",
    "    cluster_category = pd.DataFrame(clustering_result, columns=[\"cat\"])\n",
    "    return cluster_category\n",
    "\n",
    "# save data to local dir\n",
    "def save_data(cluster_data, folder_name, split_data=True):\n",
    "    Y = cluster_data[[\"label\"]]\n",
    "    X = cluster_data.drop(columns=[\"label\", \"cat\"])\n",
    "    createDir(local_data_folder + 's3/' + folder_name)\n",
    "    if split_data:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.33, random_state=1, shuffle=True)\n",
    "        pd.concat([pd.DataFrame(y_train), pd.DataFrame(x_train)], axis=1)\\\n",
    "            .to_csv(local_data_folder + 's3/' + folder_name + '/train.csv', header=False, index=False)\n",
    "        pd.concat([pd.DataFrame(y_test), pd.DataFrame(x_test)], axis=1)\\\n",
    "            .to_csv(local_data_folder + 's3/' + folder_name + '/validation.csv', header=False, index=False)\n",
    "    else:\n",
    "        pd.concat([pd.DataFrame(Y), pd.DataFrame(X)], axis=1)\\\n",
    "            .to_csv(local_data_folder + 's3/' + folder_name + '/all-test.csv', header=False, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDir(dir):\n",
    "    os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "createDir('{}s3/{}'.format(local_data_folder, ticker))\n",
    "\n",
    "# upload train and test data to S3\n",
    "dataset_with_cluster = pd.concat([pd.DataFrame(y_train, columns=[\"label\"]).astype(\"float32\"), \\\n",
    "           pd.DataFrame(x_train).astype(\"float32\"),\\\n",
    "           clustering(x_train)\n",
    "          ], axis=1)\n",
    "dataset_with_cluster.to_csv('{}s3/{}/all-train.csv'.format(local_data_folder, ticker), header=False, index=False)\n",
    "# prepare cluster data sets    \n",
    "createDir('{}s3/{}/train'.format(local_data_folder, ticker))\n",
    "save_data(dataset_with_cluster[dataset_with_cluster[\"cat\"] == 0], \"{}/train/cluster-0\".format(ticker))\n",
    "save_data(dataset_with_cluster[dataset_with_cluster[\"cat\"] == 1], \"{}/train/cluster-1\".format(ticker))\n",
    "save_data(dataset_with_cluster[dataset_with_cluster[\"cat\"] == 2], \"{}/train/cluster-2\".format(ticker))\n",
    "\n",
    "# We have to predict the clusters for each of the test data sets so that we could use it for testing out next model\n",
    "dataset_with_cluster = pd.concat([pd.DataFrame(y_test, columns=[\"label\"]).astype(\"float32\"), \\\n",
    "           pd.DataFrame(x_test).astype(\"float32\"),\\\n",
    "           clustering(x_test)\n",
    "          ], axis=1)\n",
    "dataset_with_cluster.to_csv(local_data_folder + 's3/{}/all-test.csv'.format(ticker), header=False, index=False)\n",
    "# # prepare cluster data sets    \n",
    "createDir('{}s3/{}/test'.format(local_data_folder, ticker))\n",
    "save_data(dataset_with_cluster[dataset_with_cluster[\"cat\"] == 0], \"{}/test/cluster-0\".format(ticker), False)\n",
    "save_data(dataset_with_cluster[dataset_with_cluster[\"cat\"] == 1], \"{}/test/cluster-1\".format(ticker), False)\n",
    "save_data(dataset_with_cluster[dataset_with_cluster[\"cat\"] == 2], \"{}/test/cluster-2\".format(ticker), False)\n",
    "\n",
    "# delete endpoint\n",
    "kmeans_predictor.delete_endpoint(kmeans_predictor.endpoint)\n",
    "\n",
    "print('Completed clustering for', ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -fR ./data/s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data\n",
      "Clustering\n",
      "2020-02-10 04:17:59 Starting - Starting the training job."
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "from helper.cluster import cluster_helper\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "local_data_folder = './data/'\n",
    "prefix = \"udacity-capstone-project\"\n",
    "ticker = 'A'\n",
    "\n",
    "cluster_helper(role, sagemaker_session, bucket, local_data_folder, prefix, ticker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_folder = sagemaker_session.upload_data(path=local_data_folder + 's3', bucket=bucket, key_prefix=prefix + '/data')\n",
    "s3_data_folder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
