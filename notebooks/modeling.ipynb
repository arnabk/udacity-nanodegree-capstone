{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker import KMeans\n",
    "import os\n",
    "import numpy as np\n",
    "from helper.utils import create_dir, clustering, save_data\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from glob import glob\n",
    "from sklearn.metrics import accuracy_score\n",
    "import boto3\n",
    "\n",
    "threshold = .4\n",
    "BUY = 1\n",
    "SELL = 2\n",
    "NONE = 3\n",
    "\n",
    "os.environ['AWS_PROFILE'] = \"aws-personal\"\n",
    "os.environ['AWS_DEFAULT_REGION'] = \"us-west-2\"\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "role = iam.get_role(RoleName=\"AmazonSageMaker-ExecutionRole-20191130T020687\")['Role']['Arn']\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "local_data_folder = '../data'\n",
    "prefix = \"udacity-capstone-project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_dir(dir):\n",
    "  os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "# Generate clusters for data\n",
    "def clustering(data, kmeans_predictor):\n",
    "    clustering_result = kmeans_predictor.predict(pd.DataFrame(data).astype('float32').values)\n",
    "    clustering_result = list(map(lambda x:x.label[\"closest_cluster\"].float32_tensor.values[0], clustering_result))\n",
    "\n",
    "    assert len(clustering_result) == len(data), \"Length mis-match with clustering and input data\"\n",
    "\n",
    "    cluster_category = pd.DataFrame(clustering_result, columns=[\"Cluster\"])\n",
    "    x_train_with_cluster = pd.concat([pd.DataFrame(data), cluster_category], axis=1)\n",
    "    return cluster_category\n",
    "\n",
    "# save data to local dir\n",
    "def save_data(cluster_data, folder_name):\n",
    "    Y = cluster_data[[\"Label\"]]\n",
    "    X = cluster_data.drop(columns=[\"Label\"])\n",
    "    create_dir(local_data_folder + '/s3/' + folder_name)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.33, random_state=1, shuffle=True)\n",
    "    pd.concat([pd.DataFrame(y_train), pd.DataFrame(x_train)], axis=1)\\\n",
    "        .to_csv(local_data_folder + '/s3/' + folder_name + '/train.csv', header=False, index=False)\n",
    "    pd.concat([pd.DataFrame(y_test), pd.DataFrame(x_test)], axis=1)\\\n",
    "        .to_csv(local_data_folder + '/s3/' + folder_name + '/validation.csv', header=False, index=False)\n",
    "        \n",
    "def generate_NN_predictor(ticker):\n",
    "    s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/data/{}/train.csv'\\\n",
    "                                        .format(bucket, prefix, ticker), content_type='text/csv')\n",
    "    s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/data/{}/validation.csv'\\\n",
    "                                             .format(bucket, prefix, ticker), content_type='text/csv')\n",
    "    estimator = PyTorch(entry_point='train.py',\n",
    "                        source_dir='pytorch', # this should be just \"source\" for your code\n",
    "                        role=role,\n",
    "                        framework_version='1.0',\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.c4.xlarge',\n",
    "                        sagemaker_session=sagemaker_session,\n",
    "                        hyperparameters={\n",
    "                            'input_dim': 26,  # num of features\n",
    "                            'hidden_dim': 260,\n",
    "                            'output_dim': 1,\n",
    "                            'epochs': 200 # could change to higher\n",
    "                        })\n",
    "    estimator.fit({ 'train': s3_input_train, 'validation': s3_input_validation })\n",
    "    predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")\n",
    "    return predictor\n",
    "\n",
    "def generate_random_direction():\n",
    "    rand_val = random.random()\n",
    "    direction = NONE\n",
    "    if rand_val >= .7:\n",
    "        direction = BUY\n",
    "    elif rand_val <= .3:\n",
    "        direction = SELL\n",
    "    return direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def process(ticker):\n",
    "    df = pd.read_pickle('{}/{}.{}'.format(local_data_folder, ticker, 'pkl'))\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop(columns=[\"Date\"], inplace=True)\n",
    "    df.loc[df.Label >= threshold, 'direction'] = BUY\n",
    "    df.loc[df.Label <= -threshold, 'direction'] = SELL\n",
    "    df.loc[(df.Label < threshold) & (df.Label > -threshold), 'direction'] = NONE\n",
    "\n",
    "    # Normalize\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    Y_df = pd.DataFrame(df[\"Label\"]).astype('float64')\n",
    "    X_df = df.drop(columns=[\"Label\"]).astype('float64')\n",
    "\n",
    "    X = scaler.fit_transform(X_df)\n",
    "    Y = scaler.fit_transform(Y_df)\n",
    "\n",
    "    X[:, X.shape[1] - 1] = X_df[\"direction\"].to_numpy()\n",
    "\n",
    "    #### split data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.33, random_state=1, shuffle=True)\n",
    "\n",
    "    # clustering\n",
    "    s3_output_folder = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "    kmeans = KMeans(role=role,\n",
    "                train_instance_count=1,\n",
    "                train_instance_type=\"ml.m4.xlarge\",\n",
    "                output_path=s3_output_folder,\n",
    "                k=3)\n",
    "\n",
    "    # Remove direction column and train\n",
    "    kmeans.fit(kmeans.record_set(x_train[:, 0:x_train.shape[1] - 1].astype('float32')))\n",
    "\n",
    "    # deploy\n",
    "    print(\"Deploying model\", kmeans.model_data)\n",
    "    kmeans_predictor = kmeans.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")\n",
    "\n",
    "    create_dir('{}/s3/{}'.format(local_data_folder, ticker))\n",
    "\n",
    "    '''\n",
    "        Label = Change in price(+ve, -ve, none)\n",
    "        Direction = BUY, SELL, NONE\n",
    "        Cluster = cluster_0, cluster_1, cluster_2\n",
    "    '''\n",
    "    # train data\n",
    "    y_train_df = pd.DataFrame(y_train, columns=[\"Label\"])\n",
    "    x_train_df = pd.DataFrame(x_train, columns=['col-{}'.format(i) for i in range(x_train.shape[1] - 1)] + [\"direction\"])\n",
    "    dataset_with_cluster = pd.concat([y_train_df.astype(\"float32\"), x_train_df.astype(\"float32\"),\\\n",
    "            clustering(x_train_df.drop(columns=[\"direction\"]).astype('float32').values, kmeans_predictor)\n",
    "        ], axis=1)\n",
    "    dataset_with_cluster.to_csv('{}/s3/{}/all-train.csv'.format(local_data_folder, ticker), header=True, index=False)\n",
    "\n",
    "    # test data\n",
    "    y_test_df = pd.DataFrame(y_test, columns=[\"Label\"])\n",
    "    x_test_df = pd.DataFrame(x_test, columns=['col-{}'.format(i) for i in range(x_test.shape[1] - 1)] + ['direction'])\n",
    "    pd.concat([y_test_df.astype(\"float32\"), x_test_df.astype(\"float32\")], axis=1)\\\n",
    "        .to_csv('{}/s3/{}/all-test.csv'.format(local_data_folder, ticker), header=True, index=False)\n",
    "\n",
    "    # clean clustering end point\n",
    "    kmeans_predictor.delete_endpoint(kmeans_predictor.endpoint)\n",
    "\n",
    "    all_test_pred = pd.read_csv(\"{}/s3/{}/all-test.csv\".format(local_data_folder, ticker)).dropna()\n",
    "    all_train_pred = pd.read_csv(\"{}/s3/{}/all-train.csv\".format(local_data_folder, ticker)).dropna()\n",
    "\n",
    "    cluster0_df = dataset_with_cluster[dataset_with_cluster[\"Cluster\"] == 0].drop(columns=[\"Cluster\"])\n",
    "    save_data(cluster0_df.drop(columns=[\"direction\"]), ticker)\n",
    "    sagemaker_session.upload_data(path=local_data_folder + '/s3/' + ticker, bucket=bucket, key_prefix=prefix + '/data/' + ticker)\n",
    "    estimator = generate_NN_predictor(ticker)\n",
    "    all_test_pred[\"cluster0_pred\"] = estimator.predict(all_test_pred.drop(columns=[\"Label\", \"direction\"]).astype('float32').values)\n",
    "    all_train_pred[\"cluster0_pred\"] = estimator.predict(all_train_pred.drop(columns=[\"Label\", \"direction\", \"Cluster\"]).astype('float32').values)\n",
    "    estimator.delete_endpoint(estimator.endpoint)\n",
    "\n",
    "    cluster1_df = dataset_with_cluster[dataset_with_cluster[\"Cluster\"] == 1].drop(columns=[\"Cluster\"])\n",
    "    save_data(cluster1_df.drop(columns=[\"direction\"]), ticker)\n",
    "    sagemaker_session.upload_data(path=local_data_folder + '/s3/' + ticker, bucket=bucket, key_prefix=prefix + '/data/' + ticker)\n",
    "    estimator = generate_NN_predictor(ticker)\n",
    "    all_test_pred[\"cluster1_pred\"] = estimator.predict(all_test_pred.drop(columns=[\"Label\", \"direction\", \"cluster0_pred\"]).astype('float32').values)\n",
    "    all_train_pred[\"cluster1_pred\"] = estimator.predict(all_train_pred.drop(columns=[\"Label\", \"direction\", \"Cluster\", \"cluster0_pred\"]).astype('float32').values)\n",
    "    estimator.delete_endpoint(estimator.endpoint)\n",
    "\n",
    "    cluster2_df = dataset_with_cluster[dataset_with_cluster[\"Cluster\"] == 2].drop(columns=[\"Cluster\"])\n",
    "    save_data(cluster2_df.drop(columns=[\"direction\"]), ticker)\n",
    "    sagemaker_session.upload_data(path=local_data_folder + '/s3/' + ticker, bucket=bucket, key_prefix=prefix + '/data/' + ticker)\n",
    "    estimator = generate_NN_predictor(ticker)\n",
    "    all_test_pred[\"cluster2_pred\"] = estimator.predict(all_test_pred.drop(columns=[\"Label\", \"direction\", \"cluster0_pred\", \"cluster1_pred\"]).astype('float32').values)\n",
    "    all_train_pred[\"cluster2_pred\"] = estimator.predict(all_train_pred.drop(columns=[\"Label\", \"direction\", \"Cluster\", \"cluster0_pred\", \"cluster1_pred\"]).astype('float32').values)\n",
    "    estimator.delete_endpoint(estimator.endpoint)\n",
    "\n",
    "    os.remove(local_data_folder + '/s3/' + ticker + '/train.csv')\n",
    "    os.remove(local_data_folder + '/s3/' + ticker + '/validation.csv')\n",
    "\n",
    "    all_buys = pd.DataFrame([cluster0_df[cluster0_df['direction'] == BUY].shape[0],\n",
    "            cluster1_df[cluster1_df['direction'] == BUY].shape[0],\n",
    "            cluster2_df[cluster2_df['direction'] == BUY].shape[0]], columns=[\"BUY\"], index=[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"])\n",
    "\n",
    "    all_sells = pd.DataFrame([cluster0_df[cluster0_df['direction'] == SELL].shape[0],\n",
    "            cluster1_df[cluster1_df['direction'] == SELL].shape[0],\n",
    "            cluster2_df[cluster2_df['direction'] == SELL].shape[0]], columns=[\"SELL\"], index=[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"])\n",
    "\n",
    "    all_nones = pd.DataFrame([cluster0_df[cluster0_df['direction'] == NONE].shape[0],\n",
    "            cluster1_df[cluster1_df['direction'] == NONE].shape[0],\n",
    "            cluster2_df[cluster2_df['direction'] == NONE].shape[0]], columns=[\"NONE\"], index=[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"])\n",
    "\n",
    "    cluster_selection_df = pd.concat([all_buys, all_sells, all_nones], axis=1)\n",
    "\n",
    "\n",
    "    cluster_selection_index = cluster_selection_df.index\n",
    "    buy_cluster_name = cluster_selection_index[cluster_selection_df['BUY'].values.argmax()]\n",
    "    sell_cluster_name = cluster_selection_index[cluster_selection_df.drop(index=[buy_cluster_name])['SELL'].values.argmax()]\n",
    "    none_cluster_name = cluster_selection_index[cluster_selection_df.drop(index=[buy_cluster_name, sell_cluster_name])['NONE'].values.argmax()]\n",
    "\n",
    "    # Generate selected-cluster column based on max(cluster0, cluster1, cluster2)\n",
    "    all_test_pred[\"selected-cluster\"] = all_test_pred[[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"]].idxmax(axis=1)\n",
    "    all_train_pred[\"selected-cluster\"] = all_train_pred[[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"]].idxmax(axis=1)\n",
    "\n",
    "    # convert selected-cluster to BUY, SELL, NONE\n",
    "    all_test_pred.loc[all_test_pred[\"selected-cluster\"] == buy_cluster_name, \"prediction\"] = BUY\n",
    "    all_test_pred.loc[all_test_pred[\"selected-cluster\"] == sell_cluster_name, \"prediction\"] = SELL\n",
    "    all_test_pred.loc[all_test_pred[\"selected-cluster\"] == none_cluster_name, \"prediction\"] = NONE\n",
    "\n",
    "    all_train_pred.loc[all_train_pred[\"selected-cluster\"] == buy_cluster_name, \"prediction\"] = BUY\n",
    "    all_train_pred.loc[all_train_pred[\"selected-cluster\"] == sell_cluster_name, \"prediction\"] = SELL\n",
    "    all_train_pred.loc[all_train_pred[\"selected-cluster\"] == none_cluster_name, \"prediction\"] = NONE\n",
    "\n",
    "    # Bench mark results\n",
    "    all_test_pred[\"random-prediction\"] = [generate_random_direction() for _ in range(all_test_pred.shape[0])]\n",
    "    all_train_pred[\"random-prediction\"] = [generate_random_direction() for _ in range(all_train_pred.shape[0])]\n",
    "\n",
    "\n",
    "    all_test_pred.to_csv('{}/s3/{}/all-test-pred.csv'.format(local_data_folder, ticker), index=None)\n",
    "    all_train_pred.to_csv('{}/s3/{}/all-train-pred.csv'.format(local_data_folder, ticker), index=None)\n",
    "    cluster_selection_df.to_csv('{}/s3/{}/cluster-selection.csv'.format(local_data_folder, ticker), index=None)\n",
    "    \n",
    "    # remove NA\n",
    "    all_test_pred = all_test_pred.dropna()\n",
    "    all_train_pred = all_train_pred.dropna()\n",
    "\n",
    "    # test accuracy\n",
    "    test_accuracy = accuracy_score(all_test_pred[\"direction\"], all_test_pred[\"prediction\"], normalize=True)\n",
    "    benchmark_test_accuracy = accuracy_score(all_test_pred[\"direction\"], all_test_pred[\"random-prediction\"], normalize=True)\n",
    "    print('Test accuracy:', test_accuracy, \", Benchmark:\", benchmark_test_accuracy)\n",
    "\n",
    "    # train accuracy\n",
    "    train_accuracy = accuracy_score(all_train_pred[\"direction\"], all_train_pred[\"prediction\"], normalize=True)\n",
    "    benchmark_train_accuracy = accuracy_score(all_train_pred[\"direction\"], all_train_pred[\"random-prediction\"], normalize=True)\n",
    "    print('Train accuracy:', train_accuracy, \", Benchmark:\", benchmark_train_accuracy)\n",
    "\n",
    "    accuracy_df = pd.DataFrame([ticker, test_accuracy, benchmark_test_accuracy, train_accuracy, benchmark_train_accuracy]).T\n",
    "    accuracy_df.columns = [\"ticker\", \"test_accuracy\", \"benchmark_test_accuracy\", \"train_accuracy\", \"benchmark_train_accuracy\"]\n",
    "\n",
    "    accuracy_file = \"{}/accuracy.csv\".format(local_data_folder)\n",
    "    header = not os.path.exists(accuracy_file)\n",
    "    accuracy_df.to_csv(accuracy_file, mode=\"a\", header=header, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tickers = list(map(lambda x: x.replace(local_data_folder + '/', '').replace('.csv', ''), glob(local_data_folder + \"/*.csv\")))\n",
    "\n",
    "# ValueError: Classification metrics can't handle a mix of multiclass and continuous targets\n",
    "problematic_tickers = []\n",
    "skip = [\"accuracy\", \"nyse\", \"nyse-volume\"]\n",
    "tickers = [\"AES\"]\n",
    "\n",
    "for ticker in tickers:\n",
    "    if ticker not in skip:\n",
    "        try :\n",
    "            print('Processing:', ticker)\n",
    "            process(ticker)\n",
    "        except:\n",
    "            e = sys.exc_info()\n",
    "            print(e)\n",
    "            print(\"Failed to process\", ticker)\n",
    "            problematic_tickers = problematic_tickers + [ticker]\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>col-0</th>\n",
       "      <th>col-1</th>\n",
       "      <th>col-2</th>\n",
       "      <th>col-3</th>\n",
       "      <th>col-4</th>\n",
       "      <th>col-5</th>\n",
       "      <th>col-6</th>\n",
       "      <th>col-7</th>\n",
       "      <th>col-8</th>\n",
       "      <th>...</th>\n",
       "      <th>col-23</th>\n",
       "      <th>col-24</th>\n",
       "      <th>col-25</th>\n",
       "      <th>direction</th>\n",
       "      <th>cluster0_pred</th>\n",
       "      <th>cluster1_pred</th>\n",
       "      <th>cluster2_pred</th>\n",
       "      <th>selected-cluster</th>\n",
       "      <th>prediction</th>\n",
       "      <th>random-prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.532338</td>\n",
       "      <td>0.384819</td>\n",
       "      <td>0.401575</td>\n",
       "      <td>0.394850</td>\n",
       "      <td>0.381739</td>\n",
       "      <td>0.246674</td>\n",
       "      <td>0.131345</td>\n",
       "      <td>0.483373</td>\n",
       "      <td>0.345514</td>\n",
       "      <td>0.502963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539707</td>\n",
       "      <td>0.188631</td>\n",
       "      <td>0.397627</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.538920</td>\n",
       "      <td>0.512824</td>\n",
       "      <td>0.518696</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.466593</td>\n",
       "      <td>0.734334</td>\n",
       "      <td>0.723535</td>\n",
       "      <td>0.724463</td>\n",
       "      <td>0.714783</td>\n",
       "      <td>0.726679</td>\n",
       "      <td>0.090099</td>\n",
       "      <td>0.446365</td>\n",
       "      <td>0.526126</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>...</td>\n",
       "      <td>0.509809</td>\n",
       "      <td>0.798943</td>\n",
       "      <td>0.559521</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.618808</td>\n",
       "      <td>0.542766</td>\n",
       "      <td>0.503847</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.609881</td>\n",
       "      <td>0.106796</td>\n",
       "      <td>0.125984</td>\n",
       "      <td>0.134764</td>\n",
       "      <td>0.134783</td>\n",
       "      <td>0.107266</td>\n",
       "      <td>0.106605</td>\n",
       "      <td>0.618496</td>\n",
       "      <td>0.552073</td>\n",
       "      <td>0.757223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412542</td>\n",
       "      <td>0.313620</td>\n",
       "      <td>0.458556</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.676022</td>\n",
       "      <td>0.543699</td>\n",
       "      <td>0.500737</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.599991</td>\n",
       "      <td>0.295675</td>\n",
       "      <td>0.297463</td>\n",
       "      <td>0.315880</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>0.327261</td>\n",
       "      <td>0.107681</td>\n",
       "      <td>0.546835</td>\n",
       "      <td>0.515215</td>\n",
       "      <td>0.707869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785531</td>\n",
       "      <td>0.516822</td>\n",
       "      <td>0.224095</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.502095</td>\n",
       "      <td>0.531041</td>\n",
       "      <td>0.521752</td>\n",
       "      <td>cluster1_pred</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.528030</td>\n",
       "      <td>0.225066</td>\n",
       "      <td>0.223097</td>\n",
       "      <td>0.247210</td>\n",
       "      <td>0.229565</td>\n",
       "      <td>0.177703</td>\n",
       "      <td>0.138416</td>\n",
       "      <td>0.558185</td>\n",
       "      <td>0.488005</td>\n",
       "      <td>0.588928</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210285</td>\n",
       "      <td>0.355501</td>\n",
       "      <td>0.446895</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.549786</td>\n",
       "      <td>0.572830</td>\n",
       "      <td>0.512083</td>\n",
       "      <td>cluster1_pred</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>0.523722</td>\n",
       "      <td>0.233010</td>\n",
       "      <td>0.237095</td>\n",
       "      <td>0.246352</td>\n",
       "      <td>0.241739</td>\n",
       "      <td>0.186750</td>\n",
       "      <td>0.149299</td>\n",
       "      <td>0.657267</td>\n",
       "      <td>0.410450</td>\n",
       "      <td>0.574421</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132856</td>\n",
       "      <td>0.365340</td>\n",
       "      <td>0.595813</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.540685</td>\n",
       "      <td>0.575072</td>\n",
       "      <td>0.504585</td>\n",
       "      <td>cluster1_pred</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>0.498150</td>\n",
       "      <td>0.428067</td>\n",
       "      <td>0.423447</td>\n",
       "      <td>0.436910</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.434738</td>\n",
       "      <td>0.096155</td>\n",
       "      <td>0.517686</td>\n",
       "      <td>0.439445</td>\n",
       "      <td>0.659949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856979</td>\n",
       "      <td>0.617662</td>\n",
       "      <td>0.277397</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.527641</td>\n",
       "      <td>0.532270</td>\n",
       "      <td>0.521972</td>\n",
       "      <td>cluster1_pred</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.608082</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.461067</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.452174</td>\n",
       "      <td>0.322536</td>\n",
       "      <td>0.102563</td>\n",
       "      <td>0.523919</td>\n",
       "      <td>0.539844</td>\n",
       "      <td>0.588591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700966</td>\n",
       "      <td>0.279555</td>\n",
       "      <td>0.532688</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.543163</td>\n",
       "      <td>0.507396</td>\n",
       "      <td>0.523020</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>0.675081</td>\n",
       "      <td>0.614298</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.618884</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.643621</td>\n",
       "      <td>0.082245</td>\n",
       "      <td>0.547632</td>\n",
       "      <td>0.327212</td>\n",
       "      <td>0.406166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223341</td>\n",
       "      <td>0.835858</td>\n",
       "      <td>0.445118</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.520614</td>\n",
       "      <td>0.542404</td>\n",
       "      <td>0.514606</td>\n",
       "      <td>cluster1_pred</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.519714</td>\n",
       "      <td>0.433363</td>\n",
       "      <td>0.460192</td>\n",
       "      <td>0.444635</td>\n",
       "      <td>0.460870</td>\n",
       "      <td>0.328848</td>\n",
       "      <td>0.124699</td>\n",
       "      <td>0.612290</td>\n",
       "      <td>0.441032</td>\n",
       "      <td>0.580090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202380</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>0.409087</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.545149</td>\n",
       "      <td>0.515091</td>\n",
       "      <td>0.522273</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>430 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label     col-0     col-1     col-2     col-3     col-4     col-5  \\\n",
       "2    0.532338  0.384819  0.401575  0.394850  0.381739  0.246674  0.131345   \n",
       "5    0.466593  0.734334  0.723535  0.724463  0.714783  0.726679  0.090099   \n",
       "7    0.609881  0.106796  0.125984  0.134764  0.134783  0.107266  0.106605   \n",
       "11   0.599991  0.295675  0.297463  0.315880  0.303478  0.327261  0.107681   \n",
       "12   0.528030  0.225066  0.223097  0.247210  0.229565  0.177703  0.138416   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "811  0.523722  0.233010  0.237095  0.246352  0.241739  0.186750  0.149299   \n",
       "813  0.498150  0.428067  0.423447  0.436910  0.420000  0.434738  0.096155   \n",
       "815  0.608082  0.454545  0.461067  0.472103  0.452174  0.322536  0.102563   \n",
       "816  0.675081  0.614298  0.614173  0.618884  0.608696  0.643621  0.082245   \n",
       "819  0.519714  0.433363  0.460192  0.444635  0.460870  0.328848  0.124699   \n",
       "\n",
       "        col-6     col-7     col-8  ...    col-23    col-24    col-25  \\\n",
       "2    0.483373  0.345514  0.502963  ...  0.539707  0.188631  0.397627   \n",
       "5    0.446365  0.526126  0.547170  ...  0.509809  0.798943  0.559521   \n",
       "7    0.618496  0.552073  0.757223  ...  0.412542  0.313620  0.458556   \n",
       "11   0.546835  0.515215  0.707869  ...  0.785531  0.516822  0.224095   \n",
       "12   0.558185  0.488005  0.588928  ...  0.210285  0.355501  0.446895   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "811  0.657267  0.410450  0.574421  ...  0.132856  0.365340  0.595813   \n",
       "813  0.517686  0.439445  0.659949  ...  0.856979  0.617662  0.277397   \n",
       "815  0.523919  0.539844  0.588591  ...  0.700966  0.279555  0.532688   \n",
       "816  0.547632  0.327212  0.406166  ...  0.223341  0.835858  0.445118   \n",
       "819  0.612290  0.441032  0.580090  ...  0.202380  0.293607  0.409087   \n",
       "\n",
       "     direction  cluster0_pred  cluster1_pred  cluster2_pred  selected-cluster  \\\n",
       "2          3.0       0.538920       0.512824       0.518696     cluster0_pred   \n",
       "5          3.0       0.618808       0.542766       0.503847     cluster0_pred   \n",
       "7          3.0       0.676022       0.543699       0.500737     cluster0_pred   \n",
       "11         3.0       0.502095       0.531041       0.521752     cluster1_pred   \n",
       "12         3.0       0.549786       0.572830       0.512083     cluster1_pred   \n",
       "..         ...            ...            ...            ...               ...   \n",
       "811        3.0       0.540685       0.575072       0.504585     cluster1_pred   \n",
       "813        3.0       0.527641       0.532270       0.521972     cluster1_pred   \n",
       "815        3.0       0.543163       0.507396       0.523020     cluster0_pred   \n",
       "816        3.0       0.520614       0.542404       0.514606     cluster1_pred   \n",
       "819        3.0       0.545149       0.515091       0.522273     cluster0_pred   \n",
       "\n",
       "     prediction  random-prediction  \n",
       "2           3.0                  3  \n",
       "5           3.0                  3  \n",
       "7           3.0                  2  \n",
       "11          2.0                  3  \n",
       "12          2.0                  3  \n",
       "..          ...                ...  \n",
       "811         2.0                  3  \n",
       "813         2.0                  3  \n",
       "815         3.0                  3  \n",
       "816         2.0                  2  \n",
       "819         3.0                  2  \n",
       "\n",
       "[430 rows x 34 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(local_data_folder + \"/s3/AES/all-test-pred.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
