{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sagemaker import KMeans\n",
    "import os\n",
    "import numpy as np\n",
    "from helper.utils import create_dir, clustering, save_data\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from glob import glob\n",
    "from sklearn.metrics import accuracy_score\n",
    "import boto3\n",
    "import sys\n",
    "\n",
    "threshold = .4\n",
    "BUY = 1\n",
    "SELL = 2\n",
    "NONE = 3\n",
    "\n",
    "os.environ['AWS_PROFILE'] = \"aws-personal\"\n",
    "os.environ['AWS_DEFAULT_REGION'] = \"us-west-2\"\n",
    "\n",
    "iam = boto3.client('iam')\n",
    "role = iam.get_role(RoleName=\"AmazonSageMaker-ExecutionRole-20191130T020687\")['Role']['Arn']\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "local_data_folder = './data'\n",
    "prefix = \"udacity-capstone-project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_dir(dir):\n",
    "  os.makedirs(dir, exist_ok=True)\n",
    "\n",
    "# Generate clusters for data\n",
    "def clustering(data, kmeans_predictor):\n",
    "    clustering_result = kmeans_predictor.predict(pd.DataFrame(data).astype('float32').values)\n",
    "    clustering_result = list(map(lambda x:x.label[\"closest_cluster\"].float32_tensor.values[0], clustering_result))\n",
    "\n",
    "    assert len(clustering_result) == len(data), \"Length mis-match with clustering and input data\"\n",
    "\n",
    "    cluster_category = pd.DataFrame(clustering_result, columns=[\"Cluster\"])\n",
    "    x_train_with_cluster = pd.concat([pd.DataFrame(data), cluster_category], axis=1)\n",
    "    return cluster_category\n",
    "\n",
    "# save data to local dir\n",
    "def save_data(cluster_data, folder_name):\n",
    "    Y = cluster_data[[\"Label\"]]\n",
    "    X = cluster_data.drop(columns=[\"Label\"])\n",
    "    create_dir(local_data_folder + '/s3/' + folder_name)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.33, random_state=1, shuffle=True)\n",
    "    pd.concat([pd.DataFrame(y_train), pd.DataFrame(x_train)], axis=1)\\\n",
    "        .to_csv(local_data_folder + '/s3/' + folder_name + '/train.csv', header=False, index=False)\n",
    "    pd.concat([pd.DataFrame(y_test), pd.DataFrame(x_test)], axis=1)\\\n",
    "        .to_csv(local_data_folder + '/s3/' + folder_name + '/validation.csv', header=False, index=False)\n",
    "        \n",
    "def generate_NN_predictor(ticker):\n",
    "    s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/data/{}/train.csv'\\\n",
    "                                        .format(bucket, prefix, ticker), content_type='text/csv')\n",
    "    s3_input_validation = sagemaker.s3_input(s3_data='s3://{}/{}/data/{}/validation.csv'\\\n",
    "                                             .format(bucket, prefix, ticker), content_type='text/csv')\n",
    "    estimator = PyTorch(entry_point='train.py',\n",
    "                        source_dir='pytorch', # this should be just \"source\" for your code\n",
    "                        role=role,\n",
    "                        framework_version='1.0',\n",
    "                        train_instance_count=1,\n",
    "                        train_instance_type='ml.c4.xlarge',\n",
    "                        sagemaker_session=sagemaker_session,\n",
    "                        hyperparameters={\n",
    "                            'input_dim': 26,  # num of features\n",
    "                            'hidden_dim': 260,\n",
    "                            'output_dim': 1,\n",
    "                            'epochs': 200 # could change to higher\n",
    "                        })\n",
    "    estimator.fit({ 'train': s3_input_train, 'validation': s3_input_validation })\n",
    "    predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")\n",
    "    return predictor\n",
    "\n",
    "def generate_random_direction():\n",
    "    rand_val = random.random()\n",
    "    direction = NONE\n",
    "    if rand_val >= .7:\n",
    "        direction = BUY\n",
    "    elif rand_val <= .3:\n",
    "        direction = SELL\n",
    "    return direction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def process(ticker):\n",
    "    df = pd.read_pickle('{}/{}.{}'.format(local_data_folder, ticker, 'pkl'))\n",
    "    df.dropna(inplace=True)\n",
    "    df.drop(columns=[\"Date\"], inplace=True)\n",
    "    df.loc[df.Label >= threshold, 'direction'] = BUY\n",
    "    df.loc[df.Label <= -threshold, 'direction'] = SELL\n",
    "    df.loc[(df.Label < threshold) & (df.Label > -threshold), 'direction'] = NONE\n",
    "\n",
    "    # Normalize\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    Y_df = pd.DataFrame(df[\"Label\"]).astype('float64')\n",
    "    X_df = df.drop(columns=[\"Label\"]).astype('float64')\n",
    "\n",
    "    X = scaler.fit_transform(X_df)\n",
    "    Y = scaler.fit_transform(Y_df)\n",
    "\n",
    "    X[:, X.shape[1] - 1] = X_df[\"direction\"].to_numpy()\n",
    "\n",
    "    #### split data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=.33, random_state=1, shuffle=True)\n",
    "\n",
    "    # clustering\n",
    "    s3_output_folder = \"s3://{}/{}/output\".format(bucket, prefix)\n",
    "    kmeans = KMeans(role=role,\n",
    "                train_instance_count=1,\n",
    "                train_instance_type=\"ml.m4.xlarge\",\n",
    "                output_path=s3_output_folder,\n",
    "                k=3)\n",
    "\n",
    "    # Remove direction column and train\n",
    "    kmeans.fit(kmeans.record_set(x_train[:, 0:x_train.shape[1] - 1].astype('float32')))\n",
    "\n",
    "    # deploy\n",
    "    print(\"Deploying model\", kmeans.model_data)\n",
    "    kmeans_predictor = kmeans.deploy(initial_instance_count=1, instance_type=\"ml.m4.xlarge\")\n",
    "\n",
    "    create_dir('{}/s3/{}'.format(local_data_folder, ticker))\n",
    "\n",
    "    '''\n",
    "        Label = Change in price(+ve, -ve, none)\n",
    "        Direction = BUY, SELL, NONE\n",
    "        Cluster = cluster_0, cluster_1, cluster_2\n",
    "    '''\n",
    "    # train data\n",
    "    y_train_df = pd.DataFrame(y_train, columns=[\"Label\"])\n",
    "    x_train_df = pd.DataFrame(x_train, columns=['col-{}'.format(i) for i in range(x_train.shape[1] - 1)] + [\"direction\"])\n",
    "    dataset_with_cluster = pd.concat([y_train_df.astype(\"float32\"), x_train_df.astype(\"float32\"),\\\n",
    "            clustering(x_train_df.drop(columns=[\"direction\"]).astype('float32').values, kmeans_predictor)\n",
    "        ], axis=1)\n",
    "    dataset_with_cluster.to_csv('{}/s3/{}/all-train.csv'.format(local_data_folder, ticker), header=True, index=False)\n",
    "\n",
    "    # test data\n",
    "    y_test_df = pd.DataFrame(y_test, columns=[\"Label\"])\n",
    "    x_test_df = pd.DataFrame(x_test, columns=['col-{}'.format(i) for i in range(x_test.shape[1] - 1)] + ['direction'])\n",
    "    pd.concat([y_test_df.astype(\"float32\"), x_test_df.astype(\"float32\")], axis=1)\\\n",
    "        .to_csv('{}/s3/{}/all-test.csv'.format(local_data_folder, ticker), header=True, index=False)\n",
    "\n",
    "    # clean clustering end point\n",
    "    kmeans_predictor.delete_endpoint(kmeans_predictor.endpoint)\n",
    "\n",
    "    all_test_pred = pd.read_csv(\"{}/s3/{}/all-test.csv\".format(local_data_folder, ticker)).dropna()\n",
    "    all_train_pred = pd.read_csv(\"{}/s3/{}/all-train.csv\".format(local_data_folder, ticker)).dropna()\n",
    "\n",
    "    cluster0_df = dataset_with_cluster[dataset_with_cluster[\"Cluster\"] == 0].drop(columns=[\"Cluster\"])\n",
    "    save_data(cluster0_df.drop(columns=[\"direction\"]), ticker)\n",
    "    sagemaker_session.upload_data(path=local_data_folder + '/s3/' + ticker, bucket=bucket, key_prefix=prefix + '/data/' + ticker)\n",
    "    estimator = generate_NN_predictor(ticker)\n",
    "    all_test_pred[\"cluster0_pred\"] = estimator.predict(all_test_pred.drop(columns=[\"Label\", \"direction\"]).astype('float32').values)\n",
    "    all_train_pred[\"cluster0_pred\"] = estimator.predict(all_train_pred.drop(columns=[\"Label\", \"direction\", \"Cluster\"]).astype('float32').values)\n",
    "    estimator.delete_endpoint(estimator.endpoint)\n",
    "\n",
    "    cluster1_df = dataset_with_cluster[dataset_with_cluster[\"Cluster\"] == 1].drop(columns=[\"Cluster\"])\n",
    "    save_data(cluster1_df.drop(columns=[\"direction\"]), ticker)\n",
    "    sagemaker_session.upload_data(path=local_data_folder + '/s3/' + ticker, bucket=bucket, key_prefix=prefix + '/data/' + ticker)\n",
    "    estimator = generate_NN_predictor(ticker)\n",
    "    all_test_pred[\"cluster1_pred\"] = estimator.predict(all_test_pred.drop(columns=[\"Label\", \"direction\", \"cluster0_pred\"]).astype('float32').values)\n",
    "    all_train_pred[\"cluster1_pred\"] = estimator.predict(all_train_pred.drop(columns=[\"Label\", \"direction\", \"Cluster\", \"cluster0_pred\"]).astype('float32').values)\n",
    "    estimator.delete_endpoint(estimator.endpoint)\n",
    "\n",
    "    cluster2_df = dataset_with_cluster[dataset_with_cluster[\"Cluster\"] == 2].drop(columns=[\"Cluster\"])\n",
    "    save_data(cluster2_df.drop(columns=[\"direction\"]), ticker)\n",
    "    sagemaker_session.upload_data(path=local_data_folder + '/s3/' + ticker, bucket=bucket, key_prefix=prefix + '/data/' + ticker)\n",
    "    estimator = generate_NN_predictor(ticker)\n",
    "    all_test_pred[\"cluster2_pred\"] = estimator.predict(all_test_pred.drop(columns=[\"Label\", \"direction\", \"cluster0_pred\", \"cluster1_pred\"]).astype('float32').values)\n",
    "    all_train_pred[\"cluster2_pred\"] = estimator.predict(all_train_pred.drop(columns=[\"Label\", \"direction\", \"Cluster\", \"cluster0_pred\", \"cluster1_pred\"]).astype('float32').values)\n",
    "    estimator.delete_endpoint(estimator.endpoint)\n",
    "\n",
    "    os.remove(local_data_folder + '/s3/' + ticker + '/train.csv')\n",
    "    os.remove(local_data_folder + '/s3/' + ticker + '/validation.csv')\n",
    "\n",
    "    all_buys = pd.DataFrame([cluster0_df[cluster0_df['direction'] == BUY].shape[0],\n",
    "            cluster1_df[cluster1_df['direction'] == BUY].shape[0],\n",
    "            cluster2_df[cluster2_df['direction'] == BUY].shape[0]], columns=[\"BUY\"], index=[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"])\n",
    "\n",
    "    all_sells = pd.DataFrame([cluster0_df[cluster0_df['direction'] == SELL].shape[0],\n",
    "            cluster1_df[cluster1_df['direction'] == SELL].shape[0],\n",
    "            cluster2_df[cluster2_df['direction'] == SELL].shape[0]], columns=[\"SELL\"], index=[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"])\n",
    "\n",
    "    all_nones = pd.DataFrame([cluster0_df[cluster0_df['direction'] == NONE].shape[0],\n",
    "            cluster1_df[cluster1_df['direction'] == NONE].shape[0],\n",
    "            cluster2_df[cluster2_df['direction'] == NONE].shape[0]], columns=[\"NONE\"], index=[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"])\n",
    "\n",
    "    cluster_selection_df = pd.concat([all_buys, all_sells, all_nones], axis=1)\n",
    "\n",
    "\n",
    "    cluster_selection_index = cluster_selection_df.index\n",
    "    buy_cluster_name = cluster_selection_index[cluster_selection_df['BUY'].values.argmax()]\n",
    "    sell_cluster_name = cluster_selection_index[cluster_selection_df.drop(index=[buy_cluster_name])['SELL'].values.argmax()]\n",
    "    none_cluster_name = cluster_selection_index[cluster_selection_df.drop(index=[buy_cluster_name, sell_cluster_name])['NONE'].values.argmax()]\n",
    "\n",
    "    # Generate selected-cluster column based on max(cluster0, cluster1, cluster2)\n",
    "    all_test_pred[\"selected-cluster\"] = all_test_pred[[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"]].idxmax(axis=1)\n",
    "    all_train_pred[\"selected-cluster\"] = all_train_pred[[\"cluster0_pred\", \"cluster1_pred\", \"cluster2_pred\"]].idxmax(axis=1)\n",
    "\n",
    "    # convert selected-cluster to BUY, SELL, NONE\n",
    "    all_test_pred.loc[all_test_pred[\"selected-cluster\"] == buy_cluster_name, \"prediction\"] = BUY\n",
    "    all_test_pred.loc[all_test_pred[\"selected-cluster\"] == sell_cluster_name, \"prediction\"] = SELL\n",
    "    all_test_pred.loc[all_test_pred[\"selected-cluster\"] == none_cluster_name, \"prediction\"] = NONE\n",
    "\n",
    "    all_train_pred.loc[all_train_pred[\"selected-cluster\"] == buy_cluster_name, \"prediction\"] = BUY\n",
    "    all_train_pred.loc[all_train_pred[\"selected-cluster\"] == sell_cluster_name, \"prediction\"] = SELL\n",
    "    all_train_pred.loc[all_train_pred[\"selected-cluster\"] == none_cluster_name, \"prediction\"] = NONE\n",
    "\n",
    "    # Bench mark results\n",
    "    all_test_pred[\"random-prediction\"] = [generate_random_direction() for _ in range(all_test_pred.shape[0])]\n",
    "    all_train_pred[\"random-prediction\"] = [generate_random_direction() for _ in range(all_train_pred.shape[0])]\n",
    "\n",
    "\n",
    "    all_test_pred.to_csv('{}/s3/{}/all-test-pred.csv'.format(local_data_folder, ticker), index=None)\n",
    "    all_train_pred.to_csv('{}/s3/{}/all-train-pred.csv'.format(local_data_folder, ticker), index=None)\n",
    "    cluster_selection_df.to_csv('{}/s3/{}/cluster-selection.csv'.format(local_data_folder, ticker), index=None)\n",
    "    \n",
    "    # remove NA\n",
    "    all_test_pred = all_test_pred.dropna()\n",
    "    all_train_pred = all_train_pred.dropna()\n",
    "\n",
    "    # test accuracy\n",
    "    test_accuracy = accuracy_score(all_test_pred[\"direction\"], all_test_pred[\"prediction\"], normalize=True)\n",
    "    benchmark_test_accuracy = accuracy_score(all_test_pred[\"direction\"], all_test_pred[\"random-prediction\"], normalize=True)\n",
    "    print('Test accuracy:', test_accuracy, \", Benchmark:\", benchmark_test_accuracy)\n",
    "\n",
    "    # train accuracy\n",
    "    train_accuracy = accuracy_score(all_train_pred[\"direction\"], all_train_pred[\"prediction\"], normalize=True)\n",
    "    benchmark_train_accuracy = accuracy_score(all_train_pred[\"direction\"], all_train_pred[\"random-prediction\"], normalize=True)\n",
    "    print('Train accuracy:', train_accuracy, \", Benchmark:\", benchmark_train_accuracy)\n",
    "\n",
    "    accuracy_df = pd.DataFrame([ticker, test_accuracy, benchmark_test_accuracy, train_accuracy, benchmark_train_accuracy]).T\n",
    "    accuracy_df.columns = [\"ticker\", \"test_accuracy\", \"benchmark_test_accuracy\", \"train_accuracy\", \"benchmark_train_accuracy\"]\n",
    "\n",
    "    accuracy_file = \"{}/accuracy.csv\".format(local_data_folder)\n",
    "    header = not os.path.exists(accuracy_file)\n",
    "    accuracy_df.to_csv(accuracy_file, mode=\"a\", header=header, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tickers = list(map(lambda x: x.replace(local_data_folder + '/', '').replace('.csv', ''), glob(local_data_folder + \"/*.csv\")))\n",
    "\n",
    "# ValueError: Classification metrics can't handle a mix of multiclass and continuous targets\n",
    "problematic_tickers = []\n",
    "skip = [\"accuracy\", \"nyse\", \"nyse-volume\"]\n",
    "tickers = [\"AES\"]\n",
    "\n",
    "for ticker in tickers:\n",
    "    if ticker not in skip:\n",
    "        try :\n",
    "            print('Processing:', ticker)\n",
    "            process(ticker)\n",
    "        except:\n",
    "            e = sys.exc_info()\n",
    "            print(e)\n",
    "            print(\"Failed to process\", ticker)\n",
    "            problematic_tickers = problematic_tickers + [ticker]\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>col-0</th>\n",
       "      <th>col-1</th>\n",
       "      <th>col-2</th>\n",
       "      <th>col-3</th>\n",
       "      <th>col-4</th>\n",
       "      <th>col-5</th>\n",
       "      <th>col-6</th>\n",
       "      <th>col-7</th>\n",
       "      <th>col-8</th>\n",
       "      <th>...</th>\n",
       "      <th>col-23</th>\n",
       "      <th>col-24</th>\n",
       "      <th>col-25</th>\n",
       "      <th>direction</th>\n",
       "      <th>cluster0_pred</th>\n",
       "      <th>cluster1_pred</th>\n",
       "      <th>cluster2_pred</th>\n",
       "      <th>selected-cluster</th>\n",
       "      <th>prediction</th>\n",
       "      <th>random-prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.511935</td>\n",
       "      <td>0.360988</td>\n",
       "      <td>0.371829</td>\n",
       "      <td>0.380257</td>\n",
       "      <td>0.372174</td>\n",
       "      <td>0.239941</td>\n",
       "      <td>0.158946</td>\n",
       "      <td>0.618028</td>\n",
       "      <td>0.498824</td>\n",
       "      <td>0.623892</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449553</td>\n",
       "      <td>0.231871</td>\n",
       "      <td>0.249368</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.542398</td>\n",
       "      <td>0.522937</td>\n",
       "      <td>0.481032</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.532338</td>\n",
       "      <td>0.384819</td>\n",
       "      <td>0.401575</td>\n",
       "      <td>0.394850</td>\n",
       "      <td>0.381739</td>\n",
       "      <td>0.246674</td>\n",
       "      <td>0.131345</td>\n",
       "      <td>0.483373</td>\n",
       "      <td>0.345514</td>\n",
       "      <td>0.502963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.539707</td>\n",
       "      <td>0.188631</td>\n",
       "      <td>0.397627</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.539199</td>\n",
       "      <td>0.515459</td>\n",
       "      <td>0.510398</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.434404</td>\n",
       "      <td>0.353928</td>\n",
       "      <td>0.358705</td>\n",
       "      <td>0.371674</td>\n",
       "      <td>0.360870</td>\n",
       "      <td>0.231984</td>\n",
       "      <td>0.064384</td>\n",
       "      <td>0.577224</td>\n",
       "      <td>0.470078</td>\n",
       "      <td>0.593660</td>\n",
       "      <td>...</td>\n",
       "      <td>0.851600</td>\n",
       "      <td>0.220438</td>\n",
       "      <td>0.346961</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.524654</td>\n",
       "      <td>0.521385</td>\n",
       "      <td>0.482463</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.609881</td>\n",
       "      <td>0.106796</td>\n",
       "      <td>0.125984</td>\n",
       "      <td>0.134764</td>\n",
       "      <td>0.134783</td>\n",
       "      <td>0.107266</td>\n",
       "      <td>0.106605</td>\n",
       "      <td>0.618496</td>\n",
       "      <td>0.552073</td>\n",
       "      <td>0.757223</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412542</td>\n",
       "      <td>0.313620</td>\n",
       "      <td>0.458556</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.608188</td>\n",
       "      <td>0.496879</td>\n",
       "      <td>0.468288</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.599991</td>\n",
       "      <td>0.295675</td>\n",
       "      <td>0.297463</td>\n",
       "      <td>0.315880</td>\n",
       "      <td>0.303478</td>\n",
       "      <td>0.327261</td>\n",
       "      <td>0.107681</td>\n",
       "      <td>0.546835</td>\n",
       "      <td>0.515215</td>\n",
       "      <td>0.707869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785531</td>\n",
       "      <td>0.516822</td>\n",
       "      <td>0.224095</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.550558</td>\n",
       "      <td>0.511257</td>\n",
       "      <td>0.492501</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>0.553300</td>\n",
       "      <td>0.536628</td>\n",
       "      <td>0.545932</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.552174</td>\n",
       "      <td>0.391622</td>\n",
       "      <td>0.044670</td>\n",
       "      <td>0.620375</td>\n",
       "      <td>0.559202</td>\n",
       "      <td>0.557478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.270821</td>\n",
       "      <td>0.278458</td>\n",
       "      <td>0.298696</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.533485</td>\n",
       "      <td>0.523081</td>\n",
       "      <td>0.501258</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>0.502881</td>\n",
       "      <td>0.459841</td>\n",
       "      <td>0.468066</td>\n",
       "      <td>0.450644</td>\n",
       "      <td>0.458261</td>\n",
       "      <td>0.326955</td>\n",
       "      <td>0.211389</td>\n",
       "      <td>0.519714</td>\n",
       "      <td>0.503614</td>\n",
       "      <td>0.557415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257719</td>\n",
       "      <td>0.298799</td>\n",
       "      <td>0.450694</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.542034</td>\n",
       "      <td>0.506192</td>\n",
       "      <td>0.523315</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>810</th>\n",
       "      <td>0.446648</td>\n",
       "      <td>0.200353</td>\n",
       "      <td>0.203850</td>\n",
       "      <td>0.222318</td>\n",
       "      <td>0.207826</td>\n",
       "      <td>0.124255</td>\n",
       "      <td>0.118144</td>\n",
       "      <td>0.479291</td>\n",
       "      <td>0.463690</td>\n",
       "      <td>0.667867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791532</td>\n",
       "      <td>0.167775</td>\n",
       "      <td>0.649316</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.594217</td>\n",
       "      <td>0.501045</td>\n",
       "      <td>0.487712</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>0.608082</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.461067</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.452174</td>\n",
       "      <td>0.322536</td>\n",
       "      <td>0.102563</td>\n",
       "      <td>0.523919</td>\n",
       "      <td>0.539844</td>\n",
       "      <td>0.588591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700966</td>\n",
       "      <td>0.279555</td>\n",
       "      <td>0.532688</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.526881</td>\n",
       "      <td>0.524879</td>\n",
       "      <td>0.486208</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>0.519714</td>\n",
       "      <td>0.433363</td>\n",
       "      <td>0.460192</td>\n",
       "      <td>0.444635</td>\n",
       "      <td>0.460870</td>\n",
       "      <td>0.328848</td>\n",
       "      <td>0.124699</td>\n",
       "      <td>0.612290</td>\n",
       "      <td>0.441032</td>\n",
       "      <td>0.580090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202380</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>0.409087</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.541517</td>\n",
       "      <td>0.527835</td>\n",
       "      <td>0.521534</td>\n",
       "      <td>cluster0_pred</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Label     col-0     col-1     col-2     col-3     col-4     col-5  \\\n",
       "1    0.511935  0.360988  0.371829  0.380257  0.372174  0.239941  0.158946   \n",
       "2    0.532338  0.384819  0.401575  0.394850  0.381739  0.246674  0.131345   \n",
       "4    0.434404  0.353928  0.358705  0.371674  0.360870  0.231984  0.064384   \n",
       "7    0.609881  0.106796  0.125984  0.134764  0.134783  0.107266  0.106605   \n",
       "11   0.599991  0.295675  0.297463  0.315880  0.303478  0.327261  0.107681   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "807  0.553300  0.536628  0.545932  0.549356  0.552174  0.391622  0.044670   \n",
       "808  0.502881  0.459841  0.468066  0.450644  0.458261  0.326955  0.211389   \n",
       "810  0.446648  0.200353  0.203850  0.222318  0.207826  0.124255  0.118144   \n",
       "815  0.608082  0.454545  0.461067  0.472103  0.452174  0.322536  0.102563   \n",
       "819  0.519714  0.433363  0.460192  0.444635  0.460870  0.328848  0.124699   \n",
       "\n",
       "        col-6     col-7     col-8  ...    col-23    col-24    col-25  \\\n",
       "1    0.618028  0.498824  0.623892  ...  0.449553  0.231871  0.249368   \n",
       "2    0.483373  0.345514  0.502963  ...  0.539707  0.188631  0.397627   \n",
       "4    0.577224  0.470078  0.593660  ...  0.851600  0.220438  0.346961   \n",
       "7    0.618496  0.552073  0.757223  ...  0.412542  0.313620  0.458556   \n",
       "11   0.546835  0.515215  0.707869  ...  0.785531  0.516822  0.224095   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "807  0.620375  0.559202  0.557478  ...  0.270821  0.278458  0.298696   \n",
       "808  0.519714  0.503614  0.557415  ...  0.257719  0.298799  0.450694   \n",
       "810  0.479291  0.463690  0.667867  ...  0.791532  0.167775  0.649316   \n",
       "815  0.523919  0.539844  0.588591  ...  0.700966  0.279555  0.532688   \n",
       "819  0.612290  0.441032  0.580090  ...  0.202380  0.293607  0.409087   \n",
       "\n",
       "     direction  cluster0_pred  cluster1_pred  cluster2_pred  selected-cluster  \\\n",
       "1          3.0       0.542398       0.522937       0.481032     cluster0_pred   \n",
       "2          3.0       0.539199       0.515459       0.510398     cluster0_pred   \n",
       "4          3.0       0.524654       0.521385       0.482463     cluster0_pred   \n",
       "7          3.0       0.608188       0.496879       0.468288     cluster0_pred   \n",
       "11         3.0       0.550558       0.511257       0.492501     cluster0_pred   \n",
       "..         ...            ...            ...            ...               ...   \n",
       "807        3.0       0.533485       0.523081       0.501258     cluster0_pred   \n",
       "808        3.0       0.542034       0.506192       0.523315     cluster0_pred   \n",
       "810        3.0       0.594217       0.501045       0.487712     cluster0_pred   \n",
       "815        3.0       0.526881       0.524879       0.486208     cluster0_pred   \n",
       "819        3.0       0.541517       0.527835       0.521534     cluster0_pred   \n",
       "\n",
       "     prediction  random-prediction  \n",
       "1           3.0                  2  \n",
       "2           3.0                  1  \n",
       "4           3.0                  2  \n",
       "7           3.0                  2  \n",
       "11          3.0                  3  \n",
       "..          ...                ...  \n",
       "807         3.0                  1  \n",
       "808         3.0                  2  \n",
       "810         3.0                  1  \n",
       "815         3.0                  3  \n",
       "819         3.0                  3  \n",
       "\n",
       "[380 rows x 34 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"data/s3/AES/all-test-pred.csv\").dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
